//! Analyze where the memory overhead comes from

fn main() {
    let count = 1_000_000;
    let avg_key_len = 24;
    let total_keys = count * avg_key_len;
    
    println!("=== Memory Overhead Analysis for {} keys (avg {} bytes) ===\n", count, avg_key_len);
    
    // BTreeMap analysis
    println!("BTreeMap<Vec<u8>, u64>:");
    println!("  Per key: Vec (24 bytes) + key data ({} bytes) + value (8 bytes) = {} bytes", 
             avg_key_len, 24 + avg_key_len + 8);
    println!("  Plus BTree node overhead: ~16-24 bytes/key");
    println!("  Total: ~{} bytes/key\n", 24 + avg_key_len + 8 + 20);
    
    // ART analysis  
    println!("FastArt:");
    println!("  Leaf: key_len(4) + value(8) + key_data({}) = {} bytes", avg_key_len, 12 + avg_key_len);
    println!("  Nodes: ~0.3 nodes per key Ã— 48 bytes avg = ~15 bytes");
    println!("  Path compression saves some key bytes");
    println!("  Total: ~{} bytes/key\n", 12 + avg_key_len + 15);
    
    // Theoretical minimum for mutable structure
    println!("Theoretical minimum (mutable, random insert):");
    println!("  Value: 8 bytes (u64)");
    println!("  Key discrimination: log2(N) bits for tree structure");
    println!("  For 1M keys: ~20 bits = 2.5 bytes");
    println!("  Key storage: avg {} bytes (with prefix sharing)", avg_key_len / 2);
    println!("  Total: ~{} bytes/key\n", 8 + 3 + avg_key_len / 2);
    
    println!("Current best:");
    println!("  ProperHot: ~50 bytes overhead");
    println!("  FastArt: ~57 bytes overhead");
    println!("  BTreeMap: ~70 bytes overhead");
    println!("\nConclusion: For random inserts, ~50 bytes overhead is near-optimal");
    println!("The HOT paper's 11-14 bytes was for sorted synthetic data.");
}
